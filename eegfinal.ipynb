{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a0223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# 1. Device selection (MPS, CUDA, or CPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Paths and parameters\n",
    "DATA_DIR = '/Users/kumarsatyam/Desktop/summer2025/deeplearning/final_project/chb-mit-scalp-eeg-database-1.0.0'\n",
    "RECORDS_FILE = os.path.join(DATA_DIR, 'RECORDS')\n",
    "RECORDS_WITH_SEIZURES_FILE = os.path.join(DATA_DIR, 'RECORDS-WITH-SEIZURES')\n",
    "window_sec = 5\n",
    "sfreq = 256\n",
    "window_size = window_sec * sfreq\n",
    "save_dir = \"eeg_windows\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 3. Find common channels across all files (run once)\n",
    "def get_common_channels(edf_files, max_files=20):\n",
    "    common = None\n",
    "    for i, file in enumerate(edf_files):\n",
    "        if i >= max_files:  # Limit for speed\n",
    "            break\n",
    "        raw = mne.io.read_raw_edf(os.path.join(DATA_DIR, file), preload=False, verbose=False)\n",
    "        chs = set([ch for ch in raw.ch_names if ch != '-'])\n",
    "        if common is None:\n",
    "            common = chs\n",
    "        else:\n",
    "            common = common & chs\n",
    "    return sorted(list(common))\n",
    "\n",
    "# --- Extraction: Only process missing .npz files ---\n",
    "with open(RECORDS_FILE) as f:\n",
    "    all_files = [line.strip() for line in f if line.strip()]\n",
    "with open(RECORDS_WITH_SEIZURES_FILE) as f:\n",
    "    seizure_files = set(line.strip() for line in f if line.strip())\n",
    "\n",
    "# Find common channels (intersection)\n",
    "print(\"Finding common channels...\")\n",
    "common_channels = get_common_channels(all_files, max_files=20)\n",
    "print(f\"Using {len(common_channels)} common channels: {common_channels}\")\n",
    "\n",
    "def extract_windows(file_path, label, window_size=1280):\n",
    "    raw = mne.io.read_raw_edf(os.path.join(DATA_DIR, file_path), preload=True, verbose=False)\n",
    "    # Only use channels present in both the file and the common set\n",
    "    file_chs = set(raw.ch_names)\n",
    "    pick_chs = [ch for ch in common_channels if ch in file_chs]\n",
    "    if len(pick_chs) != len(common_channels):\n",
    "        # Skip files missing any common channel\n",
    "        print(f\"Skipping {file_path}: missing channels {set(common_channels) - file_chs}\")\n",
    "        return None, None\n",
    "    raw.pick(pick_chs)\n",
    "    data = raw.get_data()\n",
    "    data = (data - np.mean(data, axis=1, keepdims=True)) / (np.std(data, axis=1, keepdims=True) + 1e-8)\n",
    "    X, y = [], []\n",
    "    for start in range(0, data.shape[1] - window_size, window_size):\n",
    "        X.append(data[:, start:start+window_size])\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Only process EDFs that don't have a corresponding .npz\n",
    "for file in tqdm(all_files, desc=\"Extracting and saving windows\"):\n",
    "    base = os.path.basename(file).replace('.edf', '')\n",
    "    npz_path = os.path.join(save_dir, f\"{base}.npz\")\n",
    "    if os.path.exists(npz_path):\n",
    "        continue  # Already processed\n",
    "    label = 1 if file in seizure_files else 0\n",
    "    Xi, yi = extract_windows(file, label, window_size)\n",
    "    if Xi is None or yi is None:\n",
    "        continue  # File skipped due to missing channels\n",
    "    np.savez_compressed(npz_path, X=Xi.astype(np.float16), y=yi.astype(np.int8))\n",
    "print(\"Extraction complete.\")\n",
    "\n",
    "# 4. Prepare file lists for train/test split\n",
    "all_npz = sorted(glob.glob(os.path.join(save_dir, \"*.npz\")))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(all_npz)\n",
    "split = int(0.8 * len(all_npz))\n",
    "train_files = all_npz[:split]\n",
    "test_files = all_npz[split:]\n",
    "\n",
    "# 5. Custom Dataset that loads windows on-the-fly\n",
    "class EEGWindowDataset(Dataset):\n",
    "    def __init__(self, npz_files):\n",
    "        self.file_map = []\n",
    "        for npzfile in npz_files:\n",
    "            with np.load(npzfile) as data:\n",
    "                n = data['X'].shape[0]\n",
    "            self.file_map.extend([(npzfile, i) for i in range(n)])\n",
    "        self.length = len(self.file_map)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        npzfile, i = self.file_map[idx]\n",
    "        with np.load(npzfile) as data:\n",
    "            x = data['X'][i].astype(np.float32)\n",
    "            y = data['y'][i].astype(np.float32)\n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "# 6. DataLoader\n",
    "train_ds = EEGWindowDataset(train_files)\n",
    "test_ds = EEGWindowDataset(test_files)\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, num_workers=4)\n",
    "\n",
    "# 7. Custom LSTM implementation\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Get n_channels and window_size from a sample\n",
    "with np.load(train_files[0]) as data:\n",
    "    n_channels = data['X'].shape[1]\n",
    "    window_size = data['X'].shape[2]\n",
    "\n",
    "class CustomLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W_ih = nn.Linear(input_size, 4 * hidden_size)\n",
    "        self.W_hh = nn.Linear(hidden_size, 4 * hidden_size)\n",
    "\n",
    "    def forward(self, x, hx):\n",
    "        h, c = hx\n",
    "        gates = self.W_ih(x) + self.W_hh(h)\n",
    "        i, f, g, o = gates.chunk(4, dim=-1)\n",
    "        i = torch.sigmoid(i)\n",
    "        f = torch.sigmoid(f)\n",
    "        g = torch.tanh(g)\n",
    "        o = torch.sigmoid(o)\n",
    "        c_next = f * c + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "class CustomLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.cell = CustomLSTMCell(input_size, hidden_size)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        h = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        c = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            h, c = self.cell(x[:, t, :], (h, c))\n",
    "            outputs.append(h.unsqueeze(1))\n",
    "        outputs = torch.cat(outputs, dim=1)  # (batch, seq_len, hidden_size)\n",
    "        return outputs, (h.unsqueeze(0), c.unsqueeze(0))\n",
    "\n",
    "class EEGNetLSTM(nn.Module):\n",
    "    def __init__(self, n_channels, window_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_channels, 32, kernel_size=7, padding=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, padding=2)\n",
    "        self.lstm = CustomLSTM(input_size=64, hidden_size=32)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        # x: (batch, channels, time)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch, 64, seq_len)\n",
    "        x = x.permute(0, 2, 1)  # (batch, seq_len, features) for LSTM\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        x = h_n[-1]  # Last hidden state\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return self.sigmoid(x).squeeze()\n",
    "\n",
    "model = EEGNetLSTM(n_channels, window_size).to(device)\n",
    "\n",
    "# 8. Training loop with tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "n_epochs = 10\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs} [Train]\", leave=False)\n",
    "    for xb, yb in train_bar:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "    train_losses.append(running_loss / len(train_loader.dataset))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(test_loader, desc=f\"Epoch {epoch+1}/{n_epochs} [Val]\", leave=False)\n",
    "        for xb, yb in val_bar:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            val_loss += loss.item() * xb.size(0)\n",
    "            val_bar.set_postfix(loss=loss.item())\n",
    "    val_losses.append(val_loss / len(test_loader.dataset))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_losses[-1]:.4f}, Val Loss={val_losses[-1]:.4f}\")\n",
    "\n",
    "# 9. Evaluation & Visualization\n",
    "model.eval()\n",
    "y_true, y_pred_prob = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        out = model(xb).cpu().numpy()\n",
    "        y_pred_prob.extend(out)\n",
    "        y_true.extend(yb.numpy())\n",
    "y_pred = (np.array(y_pred_prob) > 0.5).astype(int)\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Training curves\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "# 10. Visualize EEG Window (from test set)\n",
    "for i in range(len(test_ds)):\n",
    "    x, y = test_ds[i]\n",
    "    if y == 1:\n",
    "        idx = i\n",
    "        break\n",
    "x = x.numpy()\n",
    "plt.figure(figsize=(12, 6))\n",
    "for ch in range(x.shape[0]):\n",
    "    plt.plot(x[ch] + ch*5, label=f'Ch{ch}' if ch < 5 else None)\n",
    "plt.title(f\"EEG Window (True: 1, Pred: {int(y_pred[idx])})\")\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Amplitude (normalized)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c57bc35",
   "metadata": {},
   "source": [
    "Using device: mps\n",
    "Finding common channels...\n",
    "Using 23 common channels: ['C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP1-F7', 'FP2-F4', 'FP2-F8', 'FT10-T8', 'FT9-FT10', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P7-T7', 'P8-O2', 'T7-FT9', 'T7-P7', 'T8-P8-0', 'T8-P8-1']\n",
    "Extracting and saving windows:   0%|                                                                                 | 0/686 [00:00<?, ?it/s]Skipping chb12/chb12_27.edf: missing channels {'FP2-F4', 'FP1-F3', 'F8-T8', 'FT10-T8', 'P4-O2', 'FT9-FT10', 'P7-O1', 'FZ-CZ', 'T8-P8-1', 'P8-O2', 'T7-FT9', 'F3-C3', 'FP2-F8', 'P3-O1', 'T8-P8-0', 'F4-C4', 'FP1-F7', 'P7-T7', 'T7-P7', 'CZ-PZ', 'C3-P3', 'F7-T7', 'C4-P4'}\n",
    "Extracting and saving windows:  50%|██████████████████████████████████▌                                  | 344/686 [00:00<00:00, 1758.83it/s]Skipping chb12/chb12_28.edf: missing channels {'FP2-F4', 'FP1-F3', 'F8-T8', 'FT10-T8', 'P4-O2', 'FT9-FT10', 'P7-O1', 'FZ-CZ', 'T8-P8-1', 'P8-O2', 'T7-FT9', 'F3-C3', 'FP2-F8', 'P3-O1', 'T8-P8-0', 'F4-C4', 'FP1-F7', 'P7-T7', 'T7-P7', 'CZ-PZ', 'C3-P3', 'F7-T7', 'C4-P4'}\n",
    "Skipping chb12/chb12_29.edf: missing channels {'FP2-F4', 'FP1-F3', 'F8-T8', 'FT10-T8', 'P4-O2', 'FT9-FT10', 'P7-O1', 'FZ-CZ', 'T8-P8-1', 'P8-O2', 'T7-FT9', 'F3-C3', 'FP2-F8', 'P3-O1', 'T8-P8-0', 'F4-C4', 'FP1-F7', 'P7-T7', 'T7-P7', 'CZ-PZ', 'C3-P3', 'F7-T7', 'C4-P4'}\n",
    "Skipping chb13/chb13_04.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_05.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_06.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_07.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_08.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_09.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_10.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_11.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_12.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_13.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_14.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_15.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_16.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_18.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_24.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_30.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_36.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_37.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_38.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_39.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_40.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb13/chb13_47.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb15/chb15_01.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb16/chb16_18.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb16/chb16_19.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb17/chb17c_13.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Skipping chb18/chb18_01.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Extracting and saving windows:  76%|█████████████████████████████████████████████████████                 | 520/686 [00:03<00:01, 108.06it/s]Skipping chb19/chb19_01.edf: missing channels {'T8-P8-0', 'T8-P8-1', 'P7-T7', 'FT10-T8', 'FT9-FT10', 'T7-FT9'}\n",
    "Extracting and saving windows: 100%|██████████████████████████████████████████████████████████████████████| 686/686 [00:04<00:00, 169.44it/s]\n",
    "Extraction complete.\n",
    "Class weights - Positive: 4.00, Negative: 1.0\n",
    "Epoch 1/3:   0%|                                                                                                    | 0/8732 [00:00<?, ?it/s]Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Epoch 1/3:  26%|█████████████████████▊                                                                                                       Epoch 1/3:  96%|████████████████████████████████████████████████████████████████████████████                           Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                         Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                       Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                     Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                                Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                   Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                              Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                 Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                            Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████               Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                          Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████             Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                        Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████           Epoch 1/3:  97%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                      Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████         Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                    Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████       Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                  Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████     Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████   Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                              Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████ Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                            Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                          Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                        Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                      Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                    Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                               Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                  Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                             Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                           Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████              Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                         Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████            Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                       Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████          Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                     Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████        Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                   Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████      Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████    Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                               Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████  Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                             Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                           Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  98%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                         Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                       Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                     Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                   Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                              Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                            Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████               Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                          Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████             Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                        Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████           Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                      Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████         Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                    Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████       Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                  Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████     Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████   Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                              Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████ Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                            Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                          Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                        Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                      Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                    Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                               Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                  Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                             Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                           Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████              Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                                 Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████                                         Epoch 1/3:  99%|████████████████████████████████████████████████████████████████████████████            █████████▍| 8681/8732 [15:08:02<05:41,  6.69s/it]\n",
    "\n",
    "Epoch 1/3: 100%|██████████████████████████████████████████████████████████████████████████████████████| 8732/8732 [15:16:04<00:00,  6.29s/it]\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Epoch 1: Train Loss=1.7865, Train Acc=0.8075, Val Loss=1.9864, Val Acc=0.7885, LR=1.00e-03\n",
    "Best model saved with Val Loss=1.9864\n",
    "Epoch 2/3:   0%|                                                                                                    | 0/8732 [00:00<?, ?it/s]Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Epoch 2/3: 100%|██████████████████████████████████████████████████████████████████████████████████████| 8732/8732 [13:54:48<00:00,  5.74s/it]\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Epoch 2: Train Loss=1.2957, Train Acc=0.8573, Val Loss=2.6306, Val Acc=0.8054, LR=1.00e-03\n",
    "Epoch 3/3:   0%|                                                                                                    | 0/8732 [00:00<?, ?it/s]Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Epoch 3/3: 100%|██████████████████████████████████████████████████████████████████████████████████████| 8732/8732 [14:00:55<00:00,  5.78s/it]\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Epoch 3: Train Loss=1.1011, Train Acc=0.8772, Val Loss=3.2329, Val Acc=0.7914, LR=1.00e-03\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "Using device: mps\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.85      0.91      0.88    104649\n",
    "         1.0       0.30      0.18      0.23     21319\n",
    "\n",
    "    accuracy                           0.79    125968\n",
    "   macro avg       0.57      0.55      0.55    125968\n",
    "weighted avg       0.75      0.79      0.77    125968\n",
    "\n",
    "Test Accuracy: 0.7885"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
